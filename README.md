
# ClasificaciÃ³n de Emociones en Texto usando Machine Learning y Transformers

Este proyecto tiene como objetivo desarrollar y comparar distintos modelos de clasificaciÃ³n de emociones a partir de respuestas textuales proporcionadas por estudiantes. Se implementan tanto algoritmos tradicionales con TF-IDF como modelos de lenguaje preentrenados (Transformers) para identificar emociones como Felicidad, Tristeza, Ira, Miedo, Disgusto y Sorpresa.

## ğŸ“ Estructura del Proyecto

```
Proyecto_Emociones/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ Nuevo_Dataset_Patrones_Emocionales.csv   # Dataset original crudo
â”‚   â””â”€â”€ Dataset_Emociones_Limpio.csv             # Dataset preprocesado y etiquetado
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_EDA_Preprocesamiento.ipynb            # AnÃ¡lisis exploratorio de datos y limpieza
â”‚   â”œâ”€â”€ 02_Modelos_Tradicionales.ipynb           # ImplementaciÃ³n de SVM, KNN, NB, RF con TF-IDF
â”‚   â”œâ”€â”€ 03_Transformers_BETO_RoBERTuito.ipynb    # Fine-tuning y predicciÃ³n usando BETO y RoBERTuito
â”‚   â”œâ”€â”€ 04_Embeddings_y_ClasificaciÃ³n.ipynb      # ExtracciÃ³n de embeddings + ML tradicionales
â”‚   â””â”€â”€ 05_Modelo_MarIA.ipynb                     # Entrenamiento del modelo MarIA
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ figuras/                                 # GrÃ¡ficas comparativas generadas
â”‚   â”œâ”€â”€ metrics/                                 # Reportes de clasificaciÃ³n y mÃ©tricas por modelo
â”‚   â””â”€â”€ tablas/                                  # Tablas resumen para el documento
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ transformers_checkpoints/                # Pesos y logs de modelos fine-tuneados
â”‚
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ preprocessing.py                         # Funciones auxiliares para limpieza y tokenizaciÃ³n
â”‚
â”œâ”€â”€ README.md                                     # DescripciÃ³n del proyecto y guÃ­a de ejecuciÃ³n
â””â”€â”€ requirements.txt                              # Lista de dependencias Python del proyecto
```

## ğŸ”§ InstalaciÃ³n de Dependencias

Puedes instalar las librerÃ­as necesarias utilizando:

```bash
pip install -r requirements.txt
```

O bien desde Google Colab:

```python
!pip install -q transformers==4.30.2 datasets scikit-learn nltk wordcloud
```

## ğŸ“Œ Modelos Comparados

- **Tradicionales:** SVM, KNN, Naive Bayes, Random Forest (con TF-IDF)
- **Transformers:** BETO, RoBERTuito, MarIA
- **Embeddings:** ExtraÃ­dos desde Transformers para modelos clÃ¡sicos

## ğŸš€ EjecuciÃ³n del Proyecto

1. **Preprocesamiento de Datos:** Ejecuta `01_EDA_Preprocesamiento.ipynb`
2. **Modelos Tradicionales:** Corre `02_Modelos_Tradicionales.ipynb` para TF-IDF + SVM, NB, etc.
3. **Modelos Transformers:** Usa `03_Transformers_BETO_RoBERTuito.ipynb`
4. **Embeddings + ML Tradicional:** Ejecuta `04_Embeddings_y_ClasificaciÃ³n.ipynb`
5. **Modelo MarIA:** Corre `05_Modelo_MarIA.ipynb`

## ğŸ§  ReproducciÃ³n de Resultados

Cada notebook estÃ¡ dividido en secciones explicativas. Para reproducir los resultados:

- Cargar correctamente el dataset limpio (`Dataset_Emociones_Limpio.csv`) en la carpeta `data/`.
- Asegurarte de que las clases estÃ©n correctamente etiquetadas.
- Verifica que el entorno tenga los paquetes adecuados instalados.
- Se recomienda usar Google Colab para acceder a aceleradores como GPU.

## ğŸ“Š Salidas Esperadas

- GrÃ¡ficas comparativas (accuracy, F1-score)
- Matrices de confusiÃ³n
- Reportes de clasificaciÃ³n por modelo
- Tablas de resumen exportadas

---

Este repositorio ha sido estructurado para facilitar la lectura, ejecuciÃ³n y anÃ¡lisis de resultados. Las salidas se almacenan automÃ¡ticamente en la carpeta `results/`.

