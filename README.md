# ClasificaciÃ³n de Emociones en Texto usando Machine Learning y Transformers

Este proyecto tiene como objetivo desarrollar y comparar distintos modelos de clasificaciÃ³n de emociones a partir de respuestas textuales proporcionadas por estudiantes. Se implementan tanto algoritmos tradicionales con TF-IDF como modelos de lenguaje preentrenados (Transformers) para identificar emociones como Felicidad, Tristeza, Ira, Miedo, Disgusto y Sorpresa.

## ðŸ§ª TecnologÃ­as utilizadas

- Python 3.10
- scikit-learn
- pandas, numpy, matplotlib, seaborn
- Hugging Face Transformers
- NLTK y WordCloud
- Google Colab

## ðŸ“‚ Estructura del proyecto

- `data/`: Archivos del dataset en bruto y limpio.
- `notebooks/`: Scripts Colab organizados por etapa del proyecto.
- `utils/`: Funciones reutilizables de procesamiento de texto.
- `results/`: MÃ©tricas, grÃ¡ficas y tablas generadas.
- `models/`: Checkpoints de modelos entrenados.
- `README.md`: Esta guÃ­a.
- `requirements.txt`: Dependencias Python necesarias.

## ðŸš€ CÃ³mo ejecutar

1. Clonar el repositorio o abrir el notebook principal en Google Colab.
2. Asegurarse de cargar el dataset limpio en `data/`.
3. Ejecutar cada notebook segÃºn el orden numerado (01 â†’ 05).
4. Visualizar resultados en la carpeta `results/`.

## ðŸ“ˆ Modelos comparados

- **Algoritmos tradicionales:** SVM, KNN, Naive Bayes, Random Forest (con TF-IDF).
- **Modelos de Transformers:** BETO, RoBERTuito, MarIA.
- **Embeddings:** Representaciones generadas por modelos para alimentar clasificadores tradicionales.

## ðŸ§  Resultados esperados

Se espera que los modelos basados en Transformers superen a los tradicionales en mÃ©tricas como Accuracy y F1-macro, especialmente sin preprocesamiento agresivo. AdemÃ¡s, se evalÃºa una tercera estrategia combinando embeddings con modelos clÃ¡sicos.


